{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: graphviz in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (0.19.1)\n",
      "Requirement already satisfied: pydot in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (4.51.0)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from pydot) (2.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install graphviz pydot tqdm \n",
    "!pip install --user wandb -qqq\n",
    "#!pip install -Iv protobuf==3.12.0\n",
    "#!pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import imageio\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import save_model\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.utils.np_utils import to_categorical \n",
    "from graphviz import Digraph\n",
    "import pydot\n",
    "from PIL import Image, ImageEnhance, ImageOps\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "from os import listdir\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: dolphin_project (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\IPython\\html.py:14: ShimWarning: The `IPython.html` package has been deprecated since IPython 4.0. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  \"`IPython.html.widgets` has moved to `ipywidgets`.\", ShimWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/dolphin_project/dolphin_project%20/runs/b0e4hgot\" target=\"_blank\">helpful-darkness-5</a></strong> to <a href=\"https://wandb.ai/dolphin_project/dolphin_project%20\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/dolphin_project/dolphin_project%20/runs/b0e4hgot?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x15e9cb7a448>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Constants\n",
    "BR = 0.2\n",
    "BATCH_SIZE = 16\n",
    "ROT, SCALE = 10, 0.1\n",
    "NUM_CLASSES = 26\n",
    "DESIRED_SIZE = (218, 145)\n",
    "TRAIN_DIR = \"I:/University/Courses/Machine Learning/dolphin_dataset/\"\n",
    "LR = 0.001\n",
    "\n",
    "wandb.init(project=\"dolphin_project \",\n",
    "           config={\n",
    "               \"batch_size\": BATCH_SIZE,\n",
    "               \"lr\" : LR,\n",
    "               \"input_size\": DESIRED_SIZE,\n",
    "               \"dataset\": \"dolphin\",\n",
    "           })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjust CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>species</th>\n",
       "      <th>individual_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00021adfb725ed.jpg</td>\n",
       "      <td>melon_headed_whale</td>\n",
       "      <td>cadddb1636b9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000562241d384d.jpg</td>\n",
       "      <td>humpback_whale</td>\n",
       "      <td>1a71fbb72250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0007c33415ce37.jpg</td>\n",
       "      <td>false_killer_whale</td>\n",
       "      <td>60008f293a2b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0007d9bca26a99.jpg</td>\n",
       "      <td>bottlenose_dolphin</td>\n",
       "      <td>4b00fe572063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00087baf5cef7a.jpg</td>\n",
       "      <td>humpback_whale</td>\n",
       "      <td>8e5253662392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51028</th>\n",
       "      <td>fff639a7a78b3f.jpg</td>\n",
       "      <td>beluga</td>\n",
       "      <td>5ac053677ed1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51029</th>\n",
       "      <td>fff8b32daff17e.jpg</td>\n",
       "      <td>cuviers_beaked_whale</td>\n",
       "      <td>1184686361b3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51030</th>\n",
       "      <td>fff94675cc1aef.jpg</td>\n",
       "      <td>blue_whale</td>\n",
       "      <td>5401612696b9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51031</th>\n",
       "      <td>fffbc5dd642d8c.jpg</td>\n",
       "      <td>beluga</td>\n",
       "      <td>4000b3d7c24e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51032</th>\n",
       "      <td>fffdcd42312777.jpg</td>\n",
       "      <td>bottlenose_dolphin</td>\n",
       "      <td>4ddb2eeb5efb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51033 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    image               species individual_id\n",
       "0      00021adfb725ed.jpg    melon_headed_whale  cadddb1636b9\n",
       "1      000562241d384d.jpg        humpback_whale  1a71fbb72250\n",
       "2      0007c33415ce37.jpg    false_killer_whale  60008f293a2b\n",
       "3      0007d9bca26a99.jpg    bottlenose_dolphin  4b00fe572063\n",
       "4      00087baf5cef7a.jpg        humpback_whale  8e5253662392\n",
       "...                   ...                   ...           ...\n",
       "51028  fff639a7a78b3f.jpg                beluga  5ac053677ed1\n",
       "51029  fff8b32daff17e.jpg  cuviers_beaked_whale  1184686361b3\n",
       "51030  fff94675cc1aef.jpg            blue_whale  5401612696b9\n",
       "51031  fffbc5dd642d8c.jpg                beluga  4000b3d7c24e\n",
       "51032  fffdcd42312777.jpg    bottlenose_dolphin  4ddb2eeb5efb\n",
       "\n",
       "[51033 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adjust names to fit\n",
    "train_csv = TRAIN_DIR + \"train.csv\"\n",
    "train_df = pd.read_csv(train_csv)\n",
    "train_df.species.replace({\"globis\": \"short_finned_pilot_whale\",\n",
    "                          \"pilot_whale\": \"short_finned_pilot_whale\",\n",
    "                          \"kiler_whale\": \"killer_whale\",\n",
    "                          \"bottlenose_dolpin\": \"bottlenose_dolphin\"}, inplace=True)\n",
    "\n",
    "species_labels = list(train_df.species.unique())\n",
    "images = train_df['image']\n",
    "sid = train_df['individual_id']\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.species.unique()\n",
    "len(train_df.species.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>species</th>\n",
       "      <th>individual_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00021adfb725ed.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>cadddb1636b9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000562241d384d.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1a71fbb72250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0007c33415ce37.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>60008f293a2b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0007d9bca26a99.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>4b00fe572063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00087baf5cef7a.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>8e5253662392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51028</th>\n",
       "      <td>fff639a7a78b3f.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>5ac053677ed1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51029</th>\n",
       "      <td>fff8b32daff17e.jpg</td>\n",
       "      <td>17</td>\n",
       "      <td>1184686361b3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51030</th>\n",
       "      <td>fff94675cc1aef.jpg</td>\n",
       "      <td>7</td>\n",
       "      <td>5401612696b9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51031</th>\n",
       "      <td>fffbc5dd642d8c.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>4000b3d7c24e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51032</th>\n",
       "      <td>fffdcd42312777.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>4ddb2eeb5efb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51033 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    image  species individual_id\n",
       "0      00021adfb725ed.jpg        0  cadddb1636b9\n",
       "1      000562241d384d.jpg        1  1a71fbb72250\n",
       "2      0007c33415ce37.jpg        2  60008f293a2b\n",
       "3      0007d9bca26a99.jpg        3  4b00fe572063\n",
       "4      00087baf5cef7a.jpg        1  8e5253662392\n",
       "...                   ...      ...           ...\n",
       "51028  fff639a7a78b3f.jpg        4  5ac053677ed1\n",
       "51029  fff8b32daff17e.jpg       17  1184686361b3\n",
       "51030  fff94675cc1aef.jpg        7  5401612696b9\n",
       "51031  fffbc5dd642d8c.jpg        4  4000b3d7c24e\n",
       "51032  fffdcd42312777.jpg        3  4ddb2eeb5efb\n",
       "\n",
       "[51033 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_id(sp):\n",
    "    return species_labels.index(sp)\n",
    "##encode species\n",
    "train_df[\"species\"] = train_df.apply(lambda row :get_id(row[\"species\"]),axis = 1)\n",
    "\n",
    "##one-hot encode species\n",
    "#train_df = pd.concat([train_df, pd.get_dummies(train_df[\"species\"],prefix='species_',drop_first=True)], axis = 1)\n",
    "#train_df.drop(['species'],axis=1, inplace=True)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_and_rotate_image(im, sx, sy, deg_ccw):\n",
    "    im_orig = im\n",
    "    im = Image.new('RGBA', im_orig.size, (255, 255, 255, 255))\n",
    "    im.paste(im_orig)\n",
    "\n",
    "    w, h = im.size\n",
    "    angle = math.radians(-deg_ccw)\n",
    "\n",
    "    cos_theta = math.cos(angle)\n",
    "    sin_theta = math.sin(angle)\n",
    "\n",
    "    scaled_w, scaled_h = w * sx, h * sy\n",
    "\n",
    "    new_w = int(math.ceil(math.fabs(cos_theta * scaled_w) + math.fabs(sin_theta * scaled_h)))\n",
    "    new_h = int(math.ceil(math.fabs(sin_theta * scaled_w) + math.fabs(cos_theta * scaled_h)))\n",
    "\n",
    "    cx = w / 2.\n",
    "    cy = h / 2.\n",
    "    tx = new_w / 2.\n",
    "    ty = new_h / 2.\n",
    "\n",
    "    a = cos_theta / sx\n",
    "    b = sin_theta / sx\n",
    "    c = cx - tx * a - ty * b\n",
    "    d = -sin_theta / sy\n",
    "    e = cos_theta / sy\n",
    "    f = cy - tx * d - ty * e\n",
    "\n",
    "    return im.transform(\n",
    "        (new_w, new_h),\n",
    "        Image.AFFINE,\n",
    "        (a, b, c, d, e, f),\n",
    "        resample=Image.BILINEAR\n",
    "    )            \n",
    "\n",
    "def resize_with_crop_or_pad(im, process=False, flip=False, rotate_scale=None, br=None, non_square=None, crop=None):\n",
    "\n",
    "    old_size = im.size  # old_size[0] is in (width, height) format\n",
    "    max_dim = np.argmax(old_size)\n",
    "    ratio = float(DESIRED_SIZE[max_dim]) / old_size[max_dim]\n",
    "\n",
    "    #ratio = float(max(desired_size)) / max(old_size)\n",
    "    new_size = tuple([int(x * ratio) for x in old_size])\n",
    "    # use thumbnail() or resize() method to resize the input image\n",
    "\n",
    "    # thumbnail is a in-place operation\n",
    "\n",
    "    #im.thumbnail(new_size, Image.ANTIALIAS)\n",
    "    #im = im.resize(new_size, Image.ANTIALIAS)\n",
    "    #im = im.convert('RGB')\n",
    " \n",
    "    if crop is not None:\n",
    "        crop_value = 0.0\n",
    "        prob = np.random.uniform(0, 1)\n",
    "        if prob > 0.75:\n",
    "            crop_value = crop\n",
    "            im = ImageOps.crop(im, int(crop_value*im.size[1]))\n",
    "        elif prob > 0.5 and prob <= 0.75:\n",
    "            crop_value = crop*0.625\n",
    "        else:\n",
    "            crop_value = np.abs(np.random.uniform(0, 0.075))\n",
    "\n",
    "        im = ImageOps.crop(im, int(crop_value*im.size[1]))\n",
    "    '''\n",
    "    if rotate_scale is not None:\n",
    "        sx, sy = np.random.normal(scale=rotate_scale[1])+1, np.random.normal(scale=rotate_scale[1])+1\n",
    "        r = np.random.normal(scale=rotate_scale[0])\n",
    "        im = scale_and_rotate_image(im, sx, sy, r)\n",
    "    ''' \n",
    "\n",
    "    if br is not None:\n",
    "        b = np.random.normal(scale=br)+0.9\n",
    "        c = np.random.normal(scale=br)+0.9\n",
    "      \n",
    "        enhancerc = ImageEnhance.Contrast(im)\n",
    "        im = enhancerc.enhance(c)\n",
    "        enhancerb = ImageEnhance.Brightness(im)\n",
    "        im = enhancerb.enhance(b)\n",
    "        #im = im.resize((mobilenet_input_shape[0], mobilenet_input_shape[1]), Image.ANTIALIAS)\n",
    "\n",
    "    im = im.resize(new_size, Image.ANTIALIAS)\n",
    "\n",
    "    if flip:\n",
    "        ran = np.random.random_sample()\n",
    "\n",
    "        if ran >= 0.5:\n",
    "            im = im.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "    #im.show()\n",
    "    # create a new image and paste the resized on it\n",
    "    if non_square is not None:\n",
    "        new_im = Image.new(\"RGB\", (DESIRED_SIZE[0], DESIRED_SIZE[1]))\n",
    "        new_im.paste(im, ((DESIRED_SIZE[0] - new_size[0]) // 2,\n",
    "                        (DESIRED_SIZE[1] - new_size[1]) // 2))\n",
    "        if process:\n",
    "            new_im = np.array(new_im, dtype=np.float32) / 255.\n",
    "        else:\n",
    "            new_im = np.array(new_im, dtype=np.float32)\n",
    "        \n",
    "        return new_im[:,:,:3]\n",
    "    \n",
    "    if process:\n",
    "        im = np.array(new_im, dtype=np.float32) / 255.\n",
    "    else:\n",
    "        im = np.array(im, dtype=np.float32)\n",
    "    \n",
    "    return im[:,:,:3]\n",
    "\n",
    "def augment(im, br=None, crop=None):\n",
    "    if crop is not None:\n",
    "        crop_value = 0.0\n",
    "        prob = np.random.uniform(0, 1)\n",
    "        if prob > 0.75:\n",
    "            crop_value = crop\n",
    "            im = ImageOps.crop(im, int(crop_value*im.size[1]))\n",
    "        elif prob > 0.5 and prob <= 0.75:\n",
    "            crop_value = crop*0.625\n",
    "        else:\n",
    "            crop_value = np.abs(np.random.uniform(0, 0.075))\n",
    "\n",
    "        im = ImageOps.crop(im, int(crop_value*im.size[1]))\n",
    "        im = im.resize(DESIRED_SIZE, Image.ANTIALIAS)\n",
    "    \n",
    "    if br is not None:\n",
    "        b = np.random.normal(scale=br)+0.9\n",
    "        c = np.random.normal(scale=br)+0.9\n",
    "      \n",
    "        enhancerc = ImageEnhance.Contrast(im)\n",
    "        im = enhancerc.enhance(c)\n",
    "        enhancerb = ImageEnhance.Brightness(im)\n",
    "        im = enhancerb.enhance(b)\n",
    "    \n",
    "    im = np.array(im, dtype=np.float32)\n",
    "    return im[:,:,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# resizing dataset --- Create a folder train_images_sized and run this code one time to create the rescaled dataset\\n# WARNING THIS WILL START MODIFYING THE IMAGES IN \"train_images_sized/\"\\nfrom PIL import ImageFile\\nImageFile.LOAD_TRUNCATED_IMAGES = True\\n\\ndef resize_with_crop_or_pad_for_resizing(im, process=False, flip=False, rotate_scale=None, br=None, non_square=None, crop=None):\\n\\n    old_size = im.size  # old_size[0] is in (width, height) format\\n    max_dim = np.argmax(old_size)\\n    ratio = float(DESIRED_SIZE[max_dim]) / old_size[max_dim]\\n\\n    #ratio = float(max(desired_size)) / max(old_size)\\n    new_size = tuple([int(x * ratio) for x in old_size])\\n    # use thumbnail() or resize() method to resize the input image\\n\\n    # thumbnail is a in-place operation\\n\\n    #im.thumbnail(new_size, Image.ANTIALIAS)\\n    #im = im.resize(new_size, Image.ANTIALIAS)\\n    #im = im.convert(\\'RGB\\')\\n \\n    if crop is not None:\\n        crop_value = 0.0\\n        prob = np.random.uniform(0, 1)\\n        if prob > 0.75:\\n            crop_value = crop\\n            im = ImageOps.crop(im, int(crop_value*im.size[1]))\\n        elif prob > 0.5 and prob <= 0.75:\\n            crop_value = crop*0.625\\n        else:\\n            crop_value = np.abs(np.random.uniform(0, 0.075))\\n\\n        im = ImageOps.crop(im, int(crop_value*im.size[1]))\\n    \\n    \\n    if rotate_scale is not None:\\n        sx, sy = np.random.normal(scale=rotate_scale[1])+1, np.random.normal(scale=rotate_scale[1])+1\\n        r = np.random.normal(scale=rotate_scale[0])\\n        im = scale_and_rotate_image(im, sx, sy, r)\\n    \\n\\n    if br is not None:\\n        b = np.random.normal(scale=br)+0.9\\n        c = np.random.normal(scale=br)+0.9\\n      \\n        enhancerc = ImageEnhance.Contrast(im)\\n        im = enhancerc.enhance(c)\\n        enhancerb = ImageEnhance.Brightness(im)\\n        im = enhancerb.enhance(b)\\n        #im = im.resize((mobilenet_input_shape[0], mobilenet_input_shape[1]), Image.ANTIALIAS)\\n\\n    im = im.resize(new_size, Image.ANTIALIAS)\\n    \\n    \\n    if flip:\\n        ran = np.random.random_sample()\\n\\n        if ran >= 0.5:\\n            im = im.transpose(Image.FLIP_LEFT_RIGHT)\\n    \\n    #im.show()\\n    # create a new image and paste the resized on it\\n    if non_square is not None:\\n        new_im = Image.new(\"RGB\", (DESIRED_SIZE[0], DESIRED_SIZE[1]))\\n        new_im.paste(im, ((DESIRED_SIZE[0] - new_size[0]) // 2,\\n                        (DESIRED_SIZE[1] - new_size[1]) // 2))\\n        #if process:\\n        #    new_im = np.array(new_im, dtype=np.float32) / 255.\\n        #else:\\n        #    new_im = np.array(new_im, dtype=np.float32)\\n        \\n        return new_im#[:,:,:3]\\n    \\n    if process:\\n        im = np.array(new_im, dtype=np.float32) / 255.\\n    else:\\n        im = np.array(im, dtype=np.float32)\\n    \\n    return im[:,:,:3]\\n\\nfor i in range(len(train_df)):\\n    if os.path.isfile(TRAIN_DIR + \"train_images_sized/\" + train_df.iat[i, 0]):\\n        continue\\n    img = resize_with_crop_or_pad_for_resizing(\\n                Image.open(TRAIN_DIR + \"train_images/\" + train_df.iat[i, 0]),\\n                #process=True,\\n                #flip=True,\\n                #br=BR,\\n                #rotate_scale=(ROT, SCALE),\\n                non_square=True\\n            )\\n    img.save(TRAIN_DIR + \"train_images_sized/\" + train_df.iat[i, 0])\\n\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# resizing dataset --- Create a folder train_images_sized and run this code one time to create the rescaled dataset\n",
    "# WARNING THIS WILL START MODIFYING THE IMAGES IN \"train_images_sized/\"\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "def resize_with_crop_or_pad_for_resizing(im, process=False, flip=False, rotate_scale=None, br=None, non_square=None, crop=None):\n",
    "\n",
    "    old_size = im.size  # old_size[0] is in (width, height) format\n",
    "    max_dim = np.argmax(old_size)\n",
    "    ratio = float(DESIRED_SIZE[max_dim]) / old_size[max_dim]\n",
    "\n",
    "    #ratio = float(max(desired_size)) / max(old_size)\n",
    "    new_size = tuple([int(x * ratio) for x in old_size])\n",
    "    # use thumbnail() or resize() method to resize the input image\n",
    "\n",
    "    # thumbnail is a in-place operation\n",
    "\n",
    "    #im.thumbnail(new_size, Image.ANTIALIAS)\n",
    "    #im = im.resize(new_size, Image.ANTIALIAS)\n",
    "    #im = im.convert('RGB')\n",
    " \n",
    "    if crop is not None:\n",
    "        crop_value = 0.0\n",
    "        prob = np.random.uniform(0, 1)\n",
    "        if prob > 0.75:\n",
    "            crop_value = crop\n",
    "            im = ImageOps.crop(im, int(crop_value*im.size[1]))\n",
    "        elif prob > 0.5 and prob <= 0.75:\n",
    "            crop_value = crop*0.625\n",
    "        else:\n",
    "            crop_value = np.abs(np.random.uniform(0, 0.075))\n",
    "\n",
    "        im = ImageOps.crop(im, int(crop_value*im.size[1]))\n",
    "    \n",
    "    \n",
    "    if rotate_scale is not None:\n",
    "        sx, sy = np.random.normal(scale=rotate_scale[1])+1, np.random.normal(scale=rotate_scale[1])+1\n",
    "        r = np.random.normal(scale=rotate_scale[0])\n",
    "        im = scale_and_rotate_image(im, sx, sy, r)\n",
    "    \n",
    "\n",
    "    if br is not None:\n",
    "        b = np.random.normal(scale=br)+0.9\n",
    "        c = np.random.normal(scale=br)+0.9\n",
    "      \n",
    "        enhancerc = ImageEnhance.Contrast(im)\n",
    "        im = enhancerc.enhance(c)\n",
    "        enhancerb = ImageEnhance.Brightness(im)\n",
    "        im = enhancerb.enhance(b)\n",
    "        #im = im.resize((mobilenet_input_shape[0], mobilenet_input_shape[1]), Image.ANTIALIAS)\n",
    "\n",
    "    im = im.resize(new_size, Image.ANTIALIAS)\n",
    "    \n",
    "    \n",
    "    if flip:\n",
    "        ran = np.random.random_sample()\n",
    "\n",
    "        if ran >= 0.5:\n",
    "            im = im.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "    \n",
    "    #im.show()\n",
    "    # create a new image and paste the resized on it\n",
    "    if non_square is not None:\n",
    "        new_im = Image.new(\"RGB\", (DESIRED_SIZE[0], DESIRED_SIZE[1]))\n",
    "        new_im.paste(im, ((DESIRED_SIZE[0] - new_size[0]) // 2,\n",
    "                        (DESIRED_SIZE[1] - new_size[1]) // 2))\n",
    "        #if process:\n",
    "        #    new_im = np.array(new_im, dtype=np.float32) / 255.\n",
    "        #else:\n",
    "        #    new_im = np.array(new_im, dtype=np.float32)\n",
    "        \n",
    "        return new_im#[:,:,:3]\n",
    "    \n",
    "    if process:\n",
    "        im = np.array(new_im, dtype=np.float32) / 255.\n",
    "    else:\n",
    "        im = np.array(im, dtype=np.float32)\n",
    "    \n",
    "    return im[:,:,:3]\n",
    "\n",
    "for i in range(len(train_df)):\n",
    "    if os.path.isfile(TRAIN_DIR + \"train_images_sized/\" + train_df.iat[i, 0]):\n",
    "        continue\n",
    "    img = resize_with_crop_or_pad_for_resizing(\n",
    "                Image.open(TRAIN_DIR + \"train_images/\" + train_df.iat[i, 0]),\n",
    "                #process=True,\n",
    "                #flip=True,\n",
    "                #br=BR,\n",
    "                #rotate_scale=(ROT, SCALE),\n",
    "                non_square=True\n",
    "            )\n",
    "    img.save(TRAIN_DIR + \"train_images_sized/\" + train_df.iat[i, 0])\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45732 5302\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfor i,img in enumerate(tqdm(images)):\\n    image = cv2.imread(\"train_images/\"+img,cv2.IMREAD_GRAYSCALE)#imports pictures in grayscale since colors have own dimension\\n    image = cv2.resize(image, dsize=(64, 64), interpolation=cv2.INTER_CUBIC)\\n    #dataset.append((image,sid[i]))\\n    dataset.append(image)\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training Data\n",
    "train_df_im_labels = train_df[[\"image\", \"species\"]]\n",
    "train_df_im_labels = train_df_im_labels.sample(frac=1, random_state=113)\n",
    "X_train, X_valid = train_df_im_labels.loc[:len(train_df_im_labels)*9//10], train_df_im_labels.loc[len(train_df_im_labels)*9//10:]\n",
    "print(len(X_train), len(X_valid))\n",
    "'''\n",
    "for i,img in enumerate(tqdm(images)):\n",
    "    image = cv2.imread(\"train_images/\"+img,cv2.IMREAD_GRAYSCALE)#imports pictures in grayscale since colors have own dimension\n",
    "    image = cv2.resize(image, dsize=(64, 64), interpolation=cv2.INTER_CUBIC)\n",
    "    #dataset.append((image,sid[i]))\n",
    "    dataset.append(image)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#Testing Data\\ntest_dir = \"test_images\"\\ntest_dataset = []\\nfor img in tqdm(os.listdir(test_dir)): \\n    image = imageio.imread(\"test_images/\"+img)\\n    image = cv2.resize(image, dsize=(64, 64), interpolation=cv2.INTER_CUBIC)\\n    test_dataset.append(image)\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#Testing Data\n",
    "test_dir = \"test_images\"\n",
    "test_dataset = []\n",
    "for img in tqdm(os.listdir(test_dir)): \n",
    "    image = imageio.imread(\"test_images/\"+img)\n",
    "    image = cv2.resize(image, dsize=(64, 64), interpolation=cv2.INTER_CUBIC)\n",
    "    test_dataset.append(image)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_on_batch(model, batch_idx):\n",
    "    batch = []\n",
    "    y = []\n",
    "    for idx in batch_idx:\n",
    "        img = augment(\n",
    "                Image.open(TRAIN_DIR + \"train_images_sized/\" + train_df_im_labels.iat[idx, 0]),\n",
    "                br=BR,\n",
    "                crop=True,\n",
    "                #rotate_scale=(ROT, SCALE),\n",
    "                #non_square=True\n",
    "            )\n",
    "        #print(img.shape)\n",
    "        batch.append(\n",
    "            img\n",
    "        )\n",
    "        y.append(train_df_im_labels.iat[idx, 1])\n",
    "    \n",
    "    batch = np.array(batch)\n",
    "    #print(batch.shape)\n",
    "    y = to_categorical(y, NUM_CLASSES)\n",
    "    loss, acc = model.train_on_batch(batch, y)\n",
    "    wandb.log({\"loss\": loss, \"accuracy\": acc})\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, X_valid):\n",
    "    loss, acc = [], []\n",
    "    bs = 32\n",
    "    for b in range(len(math.ceil(X_valid/bs))):\n",
    "        for idx in range(bs):\n",
    "            img = resize_with_crop_or_pad(\n",
    "                    Image.open(TRAIN_DIR + \"train_images_sized/\" + X_valid.iat[b*bs+idx, 0]),\n",
    "                    #process=True,\n",
    "                    #flip=True,\n",
    "                    #br=BR,\n",
    "                    #rotate_scale=(ROT, SCALE),\n",
    "                    non_square=True\n",
    "                )\n",
    "            #print(img.shape)\n",
    "            batch.append(\n",
    "                img\n",
    "            )\n",
    "            y.append(train_df_im_labels.iat[b*bs+idx, 1])\n",
    "    \n",
    "        batch = np.array(batch)\n",
    "    #print(batch.shape)\n",
    "        y = to_categorical(y, NUM_CLASSES)\n",
    "        l, a = model.train_on_batch(batch, y)\n",
    "        loss.append(l)\n",
    "        acc.append(a)\n",
    "    return np.mean(loss), np.mean(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmodel = keras.Sequential([\\n    layers.Flatten(input_shape=[64, 64]),\\n    layers.Dense(512, activation=\"relu\"),\\n    layers.Dense(256, activation=\"relu\"),\\n    layers.Dense(128, activation=\"relu\"),\\n    layers.Dense(64, activation=\"relu\"),\\n    layers.Dense(26, activation=\"softmax\"),\\n])\\nmodel.summary()\\nplot_model(model,show_shapes=True, show_layer_names=True)\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#generating model\n",
    "'''\n",
    "model = keras.Sequential([\n",
    "    layers.Flatten(input_shape=[64, 64]),\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(256, activation=\"relu\"),\n",
    "    layers.Dense(128, activation=\"relu\"),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(26, activation=\"softmax\"),\n",
    "])\n",
    "model.summary()\n",
    "plot_model(model,show_shapes=True, show_layer_names=True)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 145, 218, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " sequential (Sequential)        (None, 145, 218, 3)  0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " rescaling (Rescaling)          (None, 145, 218, 3)  0           ['sequential[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 73, 109, 32)  896         ['rescaling[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 73, 109, 32)  128        ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 73, 109, 32)  0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 73, 109, 64)  18496       ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 73, 109, 64)  256        ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 73, 109, 64)  0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 73, 109, 64)  0           ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " separable_conv2d (SeparableCon  (None, 73, 109, 128  8896       ['activation_2[0][0]']           \n",
      " v2D)                           )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 73, 109, 128  512        ['separable_conv2d[0][0]']       \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 73, 109, 128  0           ['batch_normalization_2[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " separable_conv2d_1 (SeparableC  (None, 73, 109, 128  17664      ['activation_3[0][0]']           \n",
      " onv2D)                         )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 73, 109, 128  512        ['separable_conv2d_1[0][0]']     \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 37, 55, 128)  0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 37, 55, 128)  8320        ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 37, 55, 128)  0           ['max_pooling2d[0][0]',          \n",
      "                                                                  'conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 37, 55, 128)  0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " separable_conv2d_2 (SeparableC  (None, 37, 55, 256)  34176      ['activation_4[0][0]']           \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 37, 55, 256)  1024       ['separable_conv2d_2[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 37, 55, 256)  0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " separable_conv2d_3 (SeparableC  (None, 37, 55, 256)  68096      ['activation_5[0][0]']           \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 37, 55, 256)  1024       ['separable_conv2d_3[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 19, 28, 256)  0          ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 19, 28, 256)  33024       ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 19, 28, 256)  0           ['max_pooling2d_1[0][0]',        \n",
      "                                                                  'conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 19, 28, 256)  0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " separable_conv2d_4 (SeparableC  (None, 19, 28, 512)  133888     ['activation_6[0][0]']           \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 19, 28, 512)  2048       ['separable_conv2d_4[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 19, 28, 512)  0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " separable_conv2d_5 (SeparableC  (None, 19, 28, 512)  267264     ['activation_7[0][0]']           \n",
      " onv2D)                                                                                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 19, 28, 512)  2048       ['separable_conv2d_5[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 10, 14, 512)  0          ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 10, 14, 512)  131584      ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 10, 14, 512)  0           ['max_pooling2d_2[0][0]',        \n",
      "                                                                  'conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 10, 14, 512)  0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " separable_conv2d_6 (SeparableC  (None, 10, 14, 728)  378072     ['activation_8[0][0]']           \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 10, 14, 728)  2912       ['separable_conv2d_6[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 10, 14, 728)  0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " separable_conv2d_7 (SeparableC  (None, 10, 14, 728)  537264     ['activation_9[0][0]']           \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 10, 14, 728)  2912       ['separable_conv2d_7[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 5, 7, 728)   0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 5, 7, 728)    373464      ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 5, 7, 728)    0           ['max_pooling2d_3[0][0]',        \n",
      "                                                                  'conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " separable_conv2d_8 (SeparableC  (None, 5, 7, 1024)  753048      ['add_3[0][0]']                  \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 5, 7, 1024)  4096        ['separable_conv2d_8[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 5, 7, 1024)   0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 1024)        0           ['activation_10[0][0]']          \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1024)         0           ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 26)           26650       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,808,274\n",
      "Trainable params: 2,799,538\n",
      "Non-trainable params: 8,736\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_model(input_shape, num_classes):\n",
    "    # Note: input is flipped to (height, width) instead of (width, height)\n",
    "    inputs = keras.Input(shape=(input_shape[1], input_shape[0], input_shape[2]))\n",
    "    \n",
    "    data_augmentation = keras.Sequential(\n",
    "        [\n",
    "            #version tf 2.4.1: \n",
    "            layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "            layers.experimental.preprocessing.RandomRotation(0.1),\n",
    "        ]\n",
    "    )\n",
    "    # Image augmentation block\n",
    "    x = data_augmentation(inputs)\n",
    "    activation_str = \"elu\"\n",
    "    # Entry block\n",
    "    #version tf 2.4.1\n",
    "    x = layers.experimental.preprocessing.Rescaling(1.0 / 255)(x)\n",
    "    #-----------------\n",
    "    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(activation_str)(x)\n",
    "\n",
    "    x = layers.Conv2D(64, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(activation_str)(x)\n",
    "\n",
    "    previous_block_activation = x  # Set aside residual\n",
    "\n",
    "    for size in [128, 256, 512, 728]:\n",
    "        x = layers.Activation(activation_str)(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Activation(activation_str)(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(\n",
    "            previous_block_activation\n",
    "        )\n",
    "        x = layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    x = layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(activation_str)(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    if num_classes == 2:\n",
    "        activation = \"sigmoid\"\n",
    "        units = 1\n",
    "    else:\n",
    "        activation = \"softmax\"\n",
    "        units = num_classes\n",
    "\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(units, activation=activation)(x)\n",
    "    return keras.Model(inputs, outputs)\n",
    "\n",
    "#creating model\n",
    "model = create_model([DESIRED_SIZE[0], DESIRED_SIZE[1], 3], NUM_CLASSES)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compiling model\n",
    "model.compile(loss=keras.losses.CategoricalCrossentropy(),\n",
    "              optimizer=keras.optimizers.Adam(LR),                    \n",
    "              metrics=[\"accuracy\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#training model\n",
    "'''\n",
    "epochs = 20\n",
    "history = model.fit(X_train, y_train, epochs=epochs,\n",
    "                    validation_data=(X_valid, y_valid))\n",
    "#saving trained model\n",
    "model.save(\"trained_model_cnn.h5\")\n",
    "\n",
    "#with open('base_model.pkl','wb') as f:\n",
    "#    pickle.dump(model,f)\n",
    "'''\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "for e in range(epochs):\n",
    "    dataset_indexes_shuffled = np.random.permutation(np.arange(len(X_train)))\n",
    "    dataset_in_batches = [dataset_indexes_shuffled[i:i+BATCH_SIZE] \n",
    "                          for i in range(0, len(dataset_indexes_shuffled), BATCH_SIZE)]\n",
    "    len_dat_d4 = len(dataset_in_batches)//4\n",
    "    for i, batch in enumerate(dataset_in_batches):\n",
    "        loss, acc = train_on_batch(model, batch)\n",
    "        \n",
    "        if i in [len_dat_d4, len_dat_d4*2, len_dat_d4*3, len_dat_d4*4-1]:\n",
    "            loss_v, acc_v = validate(model, X_valid)\n",
    "            wandb.log({\"validation_loss\": loss_v, \"validation_accuracy\": acc_v})\n",
    "            print(f\"validation loss, acc: {loss_v}, {acc_v}\")\n",
    "        if i % 10 == 0:\n",
    "            print(f\"train loss, acc: {loss}, {acc}\")\n",
    "        if i % 50 == 0:\n",
    "            model.save(f\"trained_model_cnn_batch_{i}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize model performance\n",
    "accuracy = history.history['sparse_categorical_accuracy']\n",
    "val_accuracy = history.history['val_sparse_categorical_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(range(epochs), accuracy, \"r\", label=\"Training Accuracy\")\n",
    "plt.plot(range(epochs), val_accuracy, \"orange\", label=\"Validation Accuracy\")\n",
    "plt.plot(range(epochs), loss, \"b\", label=\"Training Loss\")\n",
    "plt.plot(range(epochs), val_loss, \"g\", label=\"Validation Loss\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "#plt.gca().set_ylim(0, 2)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate model\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model not in globals():\n",
    "    model = pickle.load(open('base_model.pkl', 'rb'))\n",
    "    \n",
    "y_proba = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
